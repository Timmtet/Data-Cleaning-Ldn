{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115ef7e4",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white'> Zoopla </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e175e1e",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white'> Sales </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65328d",
   "metadata": {},
   "source": [
    "First things first, we will import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4062122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc57114",
   "metadata": {},
   "source": [
    "Next, we will load in the dataset containing the list of postcode for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1195321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('London postcode districts.xlsx - PC DIST.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a82ab",
   "metadata": {},
   "source": [
    "Now, we will create a function called 'zoopla_sales' to scrap properties that are for sale on the Zoopla website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080b8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoopla_sales(postcodes, Trans_type, website, df):\n",
    "    \"\"\"\n",
    "    This function scrapes property data from Rightmove for a given list of postcodes and transaction type,\n",
    "    and returns the data as a pandas DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    postcodes -- a list of postcodes for which to scrape property data\n",
    "    Trans_type -- the transaction type of the properties to be scraped ('sales' or 'rent')\n",
    "    website -- the name of the website being scraped (in this case, 'Rightmove')\n",
    "    df -- an empty pandas DataFrame to store the scraped data\n",
    "\n",
    "    Returns:\n",
    "    df1 -- a pandas DataFrame containing the scraped property data\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Set the path to the ChromeDriver executable\n",
    "    s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "    \n",
    "    # Launch the ChromeDriver with the specified service\n",
    "    driver = webdriver.Chrome(service= s)\n",
    "    \n",
    "    # Navigate to the specified URL \n",
    "    driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "    # Maximize the window\n",
    "    time.sleep(2)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # Find the search bar  \n",
    "    time.sleep(2.2)\n",
    "    #search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "    try:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@id,'downshift')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    except:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@class,'_1qzmny55 _1ftx2fq8')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    \n",
    "    \n",
    "    # Click the search button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[@class='x8jo560 x8jo562 x8jo56a _1ftx2fq8'][1]\").click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize empty lists for storing scraped data\n",
    "    Trans_type = []\n",
    "    address = []\n",
    "    types = []\n",
    "    bedrooms = []\n",
    "    bathrooms = []\n",
    "    prices = []\n",
    "    desc = []\n",
    "    date_added = []\n",
    "    agent_list = []\n",
    "    property_url = []\n",
    "    website = []\n",
    "    \n",
    "    # Create an empty dataframe to store the scraped data\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "     # Setting the page number to be 1 \n",
    "    i = 1\n",
    "    while True: \n",
    "        # Scrapping data for the required features in the first page\n",
    "        time.sleep(1) \n",
    "        print(\"{} {} {} {}\".format('scraping page', i,'from', postcode ))\n",
    "        \n",
    "        time.sleep(2.1)\n",
    "        try: \n",
    "            driver.find_element(By.XPATH, \"//*[contains(@class,'u94mg1 u94mg4 u94mg9')]\").click()\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "        except:\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        time.sleep(1.4)    \n",
    "        address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "        type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "        bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "        bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "        price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "        desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "        date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "        agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "        property_url_list = driver.current_url\n",
    "        Trans_type_list = Trans_type\n",
    "        website_list = website\n",
    "        for address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item in zip(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n",
    "            address.append(address_item.text)\n",
    "            types.append(type_item.text)\n",
    "            bedrooms.append(bedroom_item.text)\n",
    "            bathrooms.append(bathroom_item.text)\n",
    "            prices.append(price_item.text)\n",
    "            desc.append(desc_item.text)\n",
    "            date_added.append(date_added_item.text)\n",
    "            agent_list.append(agent_list_item.text)\n",
    "            property_url.append(property_url_list)\n",
    "            Trans_type.append(Trans_type_list)\n",
    "            website.append(website_list)\n",
    "\n",
    "\n",
    "        time.sleep(1.3)\n",
    "        # get the height of the page\n",
    "        page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "        \n",
    "        # Cancel the pop-up window\n",
    "        j= i + 1\n",
    "        url = f'https://www.zoopla.co.uk/for-sale/property/{postcode}/?q={postcode}&search_source=home&pn={j}'\n",
    "        if len(address_list) or len(type_list) != 0:\n",
    "            driver.get(url)\n",
    "        else:\n",
    "            print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n",
    "            break\n",
    "        \n",
    "            \n",
    "        #Increment the page number\n",
    "        i += 1\n",
    "        time.sleep(1)\n",
    "                \n",
    "        \n",
    "    # Create a dataframe to store data scrapped for each postcode    \n",
    "    df1 = pd.DataFrame({'Location': postcode, 'Tansaction_Type': 'Sales','Property_Type':types, 'Address' :address, 'Bedrooms': bedrooms, 'Bathrooms':bathrooms, 'Price':prices, 'Description': desc, 'Listing_Date':date_added, 'Agent':agent_list, 'Listing_Source': 'Zoopla', 'listing_URL':property_url})\n",
    "    df1.insert(0, 'Unique_Id', [f'{postcode}S{i+1:05d}ZP' for i in range(len(df1))])\n",
    "    print('Total numbers of properties available in ' + postcode + ' is ' + str(df1.shape[0]))\n",
    "\n",
    "     # Concat the dataframe obtain for all postcodes\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    \n",
    "     # Return a dataframe\n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42071880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1 from WC1B\n",
      "scraping page 2 from WC1B\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1B\n",
      "Total numbers of properties available in WC1B is 13\n",
      "scraping page 1 from WC1E\n",
      "scraping page 2 from WC1E\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1E\n",
      "Total numbers of properties available in WC1E is 21\n",
      "scraping page 1 from WC1H\n",
      "scraping page 2 from WC1H\n",
      "scraping page 3 from WC1H\n",
      "scraping page 4 from WC1H\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1H\n",
      "Total numbers of properties available in WC1H is 40\n",
      "scraping page 1 from WC1N\n",
      "scraping page 2 from WC1N\n",
      "scraping page 3 from WC1N\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1N\n",
      "Total numbers of properties available in WC1N is 28\n",
      "scraping page 1 from WC1V\n",
      "scraping page 2 from WC1V\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1V\n",
      "Total numbers of properties available in WC1V is 10\n",
      "scraping page 1 from WC1X\n",
      "scraping page 2 from WC1X\n",
      "scraping page 3 from WC1X\n",
      "scraping page 4 from WC1X\n",
      "scraping page 5 from WC1X\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1X\n",
      "Total numbers of properties available in WC1X is 69\n",
      "scraping page 1 from WC2A\n",
      "scraping page 2 from WC2A\n",
      "scraping page 3 from WC2A\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2A\n",
      "Total numbers of properties available in WC2A is 25\n",
      "scraping page 1 from WC2B\n",
      "scraping page 2 from WC2B\n",
      "scraping page 3 from WC2B\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2B\n",
      "Total numbers of properties available in WC2B is 36\n",
      "scraping page 1 from WC2E\n",
      "scraping page 2 from WC2E\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2E\n",
      "Total numbers of properties available in WC2E is 19\n",
      "scraping page 1 from WC2H\n",
      "scraping page 2 from WC2H\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2H\n",
      "Total numbers of properties available in WC2H is 17\n",
      "scraping page 1 from WC2N\n",
      "scraping page 2 from WC2N\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2N\n",
      "Total numbers of properties available in WC2N is 22\n",
      "scraping page 1 from WC2R\n",
      "scraping page 2 from WC2R\n",
      "scraping page 3 from WC2R\n",
      "scraping page 4 from WC2R\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2R\n",
      "Total numbers of properties available in WC2R is 53\n",
      "------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS 353\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes.loc[256:]['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = zoopla_sales(postcode, 'Sales', 'Zoopla', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e44cbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Zoopla_Sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6995853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode district</th>\n",
       "      <th>Local Areas</th>\n",
       "      <th>Borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>WC1B</td>\n",
       "      <td>Bloomsbury, British Museum</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>WC1E</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>WC1H</td>\n",
       "      <td>St Pancras</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>WC1N</td>\n",
       "      <td>Great Ormond Street Hospital</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>WC1V</td>\n",
       "      <td>High Holborn</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>WC1X</td>\n",
       "      <td>Kings Cross, Finsbury (west)</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>WC2A</td>\n",
       "      <td>Lincoln's Inn Fields, Royal Courts of Justice</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>WC2B</td>\n",
       "      <td>Drury Lane, Aldwych</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>WC2E</td>\n",
       "      <td>Covent Garden</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>WC2H</td>\n",
       "      <td>Leicester Square</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>WC2N</td>\n",
       "      <td>Charing Cross</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>WC2R</td>\n",
       "      <td>Somerset House</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Postcode district                                    Local Areas  \\\n",
       "256              WC1B                     Bloomsbury, British Museum   \n",
       "257              WC1E                      University College London   \n",
       "258              WC1H                                     St Pancras   \n",
       "259              WC1N                   Great Ormond Street Hospital   \n",
       "260              WC1V                                   High Holborn   \n",
       "261              WC1X                   Kings Cross, Finsbury (west)   \n",
       "262              WC2A  Lincoln's Inn Fields, Royal Courts of Justice   \n",
       "263              WC2B                            Drury Lane, Aldwych   \n",
       "264              WC2E                                  Covent Garden   \n",
       "265              WC2H                               Leicester Square   \n",
       "266              WC2N                                  Charing Cross   \n",
       "267              WC2R                                 Somerset House   \n",
       "\n",
       "         Borough  \n",
       "256       Camden  \n",
       "257       Camden  \n",
       "258       Camden  \n",
       "259       Camden  \n",
       "260       Camden  \n",
       "261       Camden  \n",
       "262       Camden  \n",
       "263       Camden  \n",
       "264  Westminster  \n",
       "265  Westminster  \n",
       "266  Westminster  \n",
       "267  Westminster  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = codes.loc[256:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20ecf0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6 bed semi-detached house for sale', '1 bed flat for sale', '2 bed flat for sale', '3 bed terraced house for sale', '3 bed semi-detached house for sale', '1 bed flat for sale', '2 bed terraced house for sale', '5 bed detached house for sale', '3 bed link detached house for sale', '5 bed detached house for sale', '5 bed detached house for sale', 'Land for sale', '5 bed property for sale', '4 bed detached house for sale', '2 bed terraced house for sale', '6 bed detached house for sale', '3 bed flat for sale', '1 bed flat for sale', '3 bed terraced house for sale', '4 bed detached house for sale', '3 bed terraced house for sale', '3 bed terraced house for sale', '2 bed semi-detached bungalow for sale', '4 bed detached house for sale', '2 bed end terrace house for sale']\n",
      "['Bishops Avenue, Bromley, Kent BR1', 'College Road, Bromley BR1', 'Marian Gardens, Bromley, Kent BR1', 'Forde Avenue, Bromley, Kent BR1', 'Ellen Close, Bickley, Bromley BR1', 'South Street, Bromley BR1', 'Rangefield Road, Bromley BR1', 'Southborough Road, Bickley, Bromley BR1', 'Powster Road, Bromley BR1', 'Sundridge Avenue, Bromley BR1', 'Woodlands Close, Bromley BR1', 'Ethelbert Close, Bromley BR1', 'Southborough Road, Bickley, Bromley BR1', 'Westcott Close, Bromley BR1', 'Farrier Close, Bromley BR1', 'Timms Close, Bromley, Kent BR1', '28 Oaklands Road, Bromley BR1', 'Babbacombe Road, Bromley BR1', 'Brangbourne Road, Bromley, Kent BR1', 'Widmore Road, Bromley BR1', 'Plymouth Road, Bromley BR1', 'Brangbourne Road, Bromley BR1', 'Welbeck Avenue, Bromley BR1', 'Highland Road, Bromley, Kent BR1', 'Wharton Road, Bromley BR1']\n",
      "['6', '1', '2', '3', '3', '1', '2', '5', '3', '5', '5', '5', '4', '2', '6', '3', '1', '3', '4', '3', '3', '2', '4', '2']\n",
      "['2', '1', '1', '1', '2', '1', '1', '3', '1', '3', '3', '4', '1', '3', '1', '1', '2', '2', '1', '2', '1', '1']\n",
      "['£1,250,000', '£255,000', '£550,000', '£600,000', '£525,000', '£260,000', '£400,000', '£1,000,000', '£600,000', '£2,750,000', '£1,500,000', '£15,000', '£1,000,000', '£1,400,000', '£475,000', '£2,250,000', '£490,000', '£300,000', '£499,995', '£1,500,000', '£475,000', '£650,000', '£399,950', '£875,000', '£500,000']\n",
      "['Chain free and newly rennovated to an exceptional standard - a fabulous 6-bed, 3.5-Bath property in the sought after Bishops Avenue, Bromley. Open ...', 'Escape the city hustle with this stunning one-bedroom garden flat in Bromley, featuring a private outdoor oasis, luxurious bathroom, and short ...', 'Located in the prestigious Hampton Grange development in Sundridge Park and presented in stunning condition is this two double bedroom second ...', \"A very generously proportioned mid terraced three bedroom 1930's family house requiring modernisation and redecoration, which is amply reflected ...\", '*Guide Price £525,000 - £550,000* A spacious three bedroom 1970’s semi-detached house situated within a quiet cul-de-sac in the heart of Bromley ...', '** Guide Price £260,000 to £280,000 ** Leaders are pleased to present to the market this chain free one double bedroom apartment, that we feel is ...', 'A well presented three bedroom mid-terrace house situated in a quiet, residential road, ideally located for Bromley town centre. Benefitting from ...', 'Opportunity to acquire a self-build plot with planning permission pending (renewal of existing consent) for a sizable detached family residence ...', 'New to Market: Modern, Spacious and Beautifully designed newly refurbished family home with high ceilings and large back garden and a drive, with ...', 'Beautifully designed to reflect the elegant features of a Georgian villa, which was built in 2016 measuring 4995 square feet. The internal ...', 'Ref pb 0330', 'Strapline Auction Sale - 31/05/2023 A unexcavated basement space with planning permission granted for excavation of the ground to front, side and ...', 'An rare opportunity to acquire a self-build plot with planning permission pending (renewal of existing consent) for a sizable detached family ...', 'Extremely well presented, four bedroom detached property.', 'A well-presented, modern 1990s built, two double bedroom property set in a quite cul-de-sac location. The property boasts: Cloakroom, reception ...', 'Guide price £2,250,000 - £2,500,000. Chain free. Full video tour. Located just 0.4 miles from Bickley station is this superb and truly unique ...', 'A well-presented three bedroom first floor apartment (1,019sqft) situated in a highly popular area of Bromley. With its high ceilings, the ...', 'Located on a residential road in Bromley town centre is this spacious one double bedroom ground floor apartment. Energy Efficiency Rating D.', 'Capital Estate Agents are pleased to offer to the market this solid 1930s mid terrace property located on a popular residential road, within close ...', 'This elegant 4 bedroom detached house boasts ample living with 2 bright reception rooms, modern kitchen, 3 stylish bathrooms, lovely south-facing ...', '**Guide Price £475,000 to £500,000** Offered to the market Chain Free and located in the heart of the much sought after Bromley Old Town is this ...', 'Beautiful 3 bedroom house in a cul-de-sac with front and rear gardens, conservatory, garage. Close to Beckenham British Rail. 20 minutes to London ...', '*** chain free *** Nestled in the heart of Bromley, this charming 2-bedroom semi-detached bungalow eagerly awaits its next owner to unleash its ...', 'Capital Estate Agents are pleased to offer to the market this detached new build house located on its own secluded plot, offered chain free and ...', \"A charming, two bedroom, end of terrace, halls adjoining cottage centrally located in the highly sought after 'Bromley Old Town' with its range of ...\"]\n",
      "['Listed on 18th May 2023', 'Listed on 18th May 2023', 'Listed on 18th May 2023', 'Listed on 18th May 2023', 'Listed on 18th May 2023', 'Available immediately', 'Listed on 17th May 2023', 'Listed on 17th May 2023', 'Listed on 17th May 2023', 'Listed on 17th May 2023', 'Listed on 17th May 2023', 'Available immediately', 'Listed on 17th May 2023', 'Listed on 16th May 2023', 'Listed on 16th May 2023', 'Listed on 16th May 2023', 'Listed on 16th May 2023', 'Listed on 16th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Available immediately', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023', 'Listed on 15th May 2023']\n",
      "['Keller Williams Advantage', '1st Choice Estates Ltd', 'Sinclair Hammelton - Bromley Sales', 'Sinclair Hammelton - Bromley Sales', 'Langford Russell - Bromley', 'Leaders - Beckenham', 'Purplebricks, Head Office', 'Hunters - Chislehurst and Bromley', 'Yopa', 'Langford Russell - Bromley', 'eXp World UK', 'Savills - National Auctions', 'Hunters - Chislehurst and Bromley', 'jdm Estate Agents', 'Alan De Maid - Bromley', 'Nested Ltd', 'Purplebricks, Head Office', 'Langford Russell - Bromley', 'Capital Bromley', 'Foxtons - Bromley', 'jdm Estate Agents', 'Panther International Properties', 'Cockburn Estate Agents', 'Capital Bromley', 'Alan De Maid - Bromley']\n",
      "25\n",
      "25\n",
      "24\n",
      "22\n",
      "25\n",
      "25\n",
      "28\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import undetected_chromedriver as webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to the ChromeDriver executable\n",
    "s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "\n",
    "# Launch the ChromeDriver with the specified service\n",
    "driver = webdriver.Chrome(service= s)\n",
    "\n",
    "# Navigate to the specified URL \n",
    "driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "# Click to cancel the pop-up window and maximize the window\n",
    "#driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div/div/div[2]/button').click()\n",
    "time.sleep(2)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Find the search bar  \n",
    "time.sleep(1.2)\n",
    "search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "search.send_keys('BR1')\n",
    "time.sleep(1.3)\n",
    "\n",
    "# Click the search button\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[2]/button').click()\n",
    "\n",
    "time.sleep(3)\n",
    "Trans_type = []\n",
    "address = []\n",
    "types = []\n",
    "bedrooms = []\n",
    "bathrooms = []\n",
    "prices = []\n",
    "desc = []\n",
    "date_added = []\n",
    "agent_list = []\n",
    "property_url = []\n",
    "website = []\n",
    "\n",
    "address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "\n",
    "for ad in address_list:\n",
    "    address.append(ad.text)\n",
    "print(address)\n",
    "\n",
    "                          \n",
    "for ad in type_list:\n",
    "    types.append(ad.text)\n",
    "print(types)                                  \n",
    "\n",
    "for ad in bedroom_list:\n",
    "    bedrooms.append(ad.text)\n",
    "print(bedrooms)\n",
    "                              \n",
    "for ad in bathroom_list:\n",
    "    bathrooms.append(ad.text)\n",
    "print(bathrooms)\n",
    "\n",
    "\n",
    "for ad in price_list:\n",
    "    prices.append(ad.text)\n",
    "print(prices)\n",
    "\n",
    "\n",
    "for ad in desc_list:\n",
    "    desc.append(ad.text)\n",
    "print(desc)\n",
    "\n",
    "\n",
    "for ad in date_added_list:\n",
    "    date_added.append(ad.text)\n",
    "print(date_added)\n",
    "\n",
    "for ad in agent_list_list:\n",
    "    agent_list.append(ad.get_attribute('alt'))\n",
    "print(agent_list)\n",
    "\n",
    "print(len(address))\n",
    "print(len(types))\n",
    "print(len(bedrooms))\n",
    "print(len(bathrooms))\n",
    "print(len(prices))\n",
    "print(len(desc))\n",
    "print(len(date_added))\n",
    "print(len(agent_list))\n",
    "\n",
    "url = 'https://www.zoopla.co.uk/for-sale/property/br1/?q=BR1&search_source=home&pn=2'\n",
    "if len(address_list) and len(type_list) != 0:\n",
    "    driver.get(url)\n",
    "else:\n",
    "    print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72edbcd",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white'> Rent </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5be01",
   "metadata": {},
   "source": [
    "Now, we will create a function called 'zoopla_rent' to scrap properties that are for rent on the Zoopla website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91431634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoopla_rent(postcodes, Trans_type, website, df):\n",
    "    \"\"\"\n",
    "    This function scrapes property data from Rightmove for a given list of postcodes and transaction type,\n",
    "    and returns the data as a pandas DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    postcodes -- a list of postcodes for which to scrape property data\n",
    "    Trans_type -- the transaction type of the properties to be scraped ('sales' or 'rent')\n",
    "    website -- the name of the website being scraped (in this case, 'Rightmove')\n",
    "    df -- an empty pandas DataFrame to store the scraped data\n",
    "\n",
    "    Returns:\n",
    "    df1 -- a pandas DataFrame containing the scraped property data\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Set the path to the ChromeDriver executable\n",
    "    s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "    \n",
    "    # Launch the ChromeDriver with the specified service\n",
    "    driver = webdriver.Chrome(service= s)\n",
    "    \n",
    "    # Navigate to the specified URL \n",
    "    driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "    # Maximize the window\n",
    "    time.sleep(2)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    #Click the rent button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[contains(@id,'radix-:Reckt6:-trigger-to-rent')]\").click()\n",
    "\n",
    "    # Find the search bar  \n",
    "    time.sleep(2.2)\n",
    "    #search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "    try:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@id,'downshift')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    except:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@class,'_1qzmny55 _1ftx2fq8')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    \n",
    "    \n",
    "    # Click the search button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[@class='x8jo560 x8jo562 x8jo56a _1ftx2fq8'][1]\").click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize empty lists for storing scraped data\n",
    "    Trans_type = []\n",
    "    address = []\n",
    "    types = []\n",
    "    bedrooms = []\n",
    "    bathrooms = []\n",
    "    prices = []\n",
    "    desc = []\n",
    "    date_added = []\n",
    "    agent_list = []\n",
    "    property_url = []\n",
    "    website = []\n",
    "    \n",
    "    # Create an empty dataframe to store the scraped data\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "     # Setting the page number to be 1 \n",
    "    i = 1\n",
    "    while True: \n",
    "        # Scrapping data for the required features in the first page\n",
    "        time.sleep(1) \n",
    "        print(\"{} {} {} {}\".format('scraping page', i,'from', postcode ))\n",
    "        \n",
    "        time.sleep(2.1)\n",
    "        try: \n",
    "            driver.find_element(By.XPATH, \"//*[contains(@class,'u94mg1 u94mg4 u94mg9')]\").click()\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "        except:\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        time.sleep(1.4)    \n",
    "        address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "        type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "        bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "        bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "        price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "        desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "        date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "        agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "        property_url_list = driver.current_url\n",
    "        Trans_type_list = Trans_type\n",
    "        website_list = website\n",
    "        for address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item in zip(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n",
    "            address.append(address_item.text)\n",
    "            types.append(type_item.text)\n",
    "            bedrooms.append(bedroom_item.text)\n",
    "            bathrooms.append(bathroom_item.text)\n",
    "            prices.append(price_item.text)\n",
    "            desc.append(desc_item.text)\n",
    "            date_added.append(date_added_item.text)\n",
    "            agent_list.append(agent_list_item.text)\n",
    "            property_url.append(property_url_list)\n",
    "            Trans_type.append(Trans_type_list)\n",
    "            website.append(website_list)\n",
    "\n",
    "\n",
    "        time.sleep(1.3)\n",
    "        # get the height of the page\n",
    "        page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "        \n",
    "        # Cancel the pop-up window\n",
    "        j= i + 1        \n",
    "        url = f'https://www.zoopla.co.uk/to-rent/property/{postcode}/?price_frequency=per_month&q={postcode}&search_source=home&pn={j}'\n",
    "        if len(address_list) or len(type_list) != 0:\n",
    "            driver.get(url)\n",
    "        else:\n",
    "            print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n",
    "            break\n",
    "        \n",
    "            \n",
    "        #Increment the page number\n",
    "        i += 1\n",
    "        time.sleep(1)\n",
    "                \n",
    "        \n",
    "    # Create a dataframe to store data scrapped for each postcode    \n",
    "    df1 = pd.DataFrame({'Location': postcode, 'Tansaction_Type': 'Rent','Property_Type':types, 'Address' :address, 'Bedrooms': bedrooms, 'Bathrooms':bathrooms, 'Price':prices, 'Description': desc, 'Listing_Date':date_added, 'Agent':agent_list, 'Listing_Source': 'Zoopla', 'listing_URL':property_url})\n",
    "    df1.insert(0, 'Unique_Id', [f'{postcode}R{i+1:05d}ZP' for i in range(len(df1))])\n",
    "    print('Total numbers of properties available in ' + postcode + ' is ' + str(df1.shape[0]))\n",
    "\n",
    "     # Concat the dataframe obtain for all postcodes\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    \n",
    "     # Return a dataframe\n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29b459a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1 from SW7\n",
      "scraping page 2 from SW7\n",
      "scraping page 3 from SW7\n",
      "scraping page 4 from SW7\n",
      "scraping page 5 from SW7\n",
      "scraping page 6 from SW7\n",
      "scraping page 7 from SW7\n",
      "scraping page 8 from SW7\n",
      "scraping page 9 from SW7\n",
      "scraping page 10 from SW7\n",
      "scraping page 11 from SW7\n",
      "scraping page 12 from SW7\n",
      "scraping page 13 from SW7\n",
      "scraping page 14 from SW7\n",
      "scraping page 15 from SW7\n",
      "scraping page 16 from SW7\n",
      "scraping page 17 from SW7\n",
      "scraping page 18 from SW7\n",
      "scraping page 19 from SW7\n",
      "scraping page 20 from SW7\n",
      "scraping page 21 from SW7\n",
      "scraping page 22 from SW7\n",
      "scraping page 23 from SW7\n",
      "scraping page 24 from SW7\n",
      "scraping page 25 from SW7\n",
      "scraping page 26 from SW7\n",
      "scraping page 27 from SW7\n",
      "scraping page 28 from SW7\n",
      "scraping page 29 from SW7\n",
      "scraping page 30 from SW7\n",
      "scraping page 31 from SW7\n",
      "scraping page 32 from SW7\n",
      "scraping page 33 from SW7\n",
      "------------------------------- SCRAPING COMPLETED FOR SW7\n",
      "Total numbers of properties available in SW7 is 575\n",
      "scraping page 1 from SW8\n",
      "scraping page 2 from SW8\n",
      "scraping page 3 from SW8\n",
      "scraping page 4 from SW8\n",
      "scraping page 5 from SW8\n",
      "scraping page 6 from SW8\n",
      "scraping page 7 from SW8\n",
      "scraping page 8 from SW8\n",
      "scraping page 9 from SW8\n",
      "scraping page 10 from SW8\n",
      "scraping page 11 from SW8\n",
      "scraping page 12 from SW8\n",
      "scraping page 13 from SW8\n",
      "scraping page 14 from SW8\n",
      "scraping page 15 from SW8\n",
      "scraping page 16 from SW8\n",
      "scraping page 17 from SW8\n",
      "------------------------------- SCRAPING COMPLETED FOR SW8\n",
      "Total numbers of properties available in SW8 is 290\n",
      "scraping page 1 from SW9\n",
      "scraping page 2 from SW9\n",
      "scraping page 3 from SW9\n",
      "scraping page 4 from SW9\n",
      "scraping page 5 from SW9\n",
      "scraping page 6 from SW9\n",
      "------------------------------- SCRAPING COMPLETED FOR SW9\n",
      "Total numbers of properties available in SW9 is 70\n",
      "scraping page 1 from TN14\n",
      "scraping page 2 from TN14\n",
      "------------------------------- SCRAPING COMPLETED FOR TN14\n",
      "Total numbers of properties available in TN14 is 9\n",
      "scraping page 1 from TN16\n",
      "scraping page 2 from TN16\n",
      "------------------------------- SCRAPING COMPLETED FOR TN16\n",
      "Total numbers of properties available in TN16 is 18\n",
      "scraping page 1 from TW1\n",
      "scraping page 2 from TW1\n",
      "scraping page 3 from TW1\n",
      "scraping page 4 from TW1\n",
      "scraping page 5 from TW1\n",
      "------------------------------- SCRAPING COMPLETED FOR TW1\n",
      "Total numbers of properties available in TW1 is 70\n",
      "scraping page 1 from TW10\n",
      "scraping page 2 from TW10\n",
      "scraping page 3 from TW10\n",
      "scraping page 4 from TW10\n",
      "------------------------------- SCRAPING COMPLETED FOR TW10\n",
      "Total numbers of properties available in TW10 is 45\n",
      "scraping page 1 from TW11\n",
      "scraping page 2 from TW11\n",
      "scraping page 3 from TW11\n",
      "scraping page 4 from TW11\n",
      "scraping page 5 from TW11\n",
      "------------------------------- SCRAPING COMPLETED FOR TW11\n",
      "Total numbers of properties available in TW11 is 55\n",
      "scraping page 1 from TW12\n",
      "scraping page 2 from TW12\n",
      "scraping page 3 from TW12\n",
      "------------------------------- SCRAPING COMPLETED FOR TW12\n",
      "Total numbers of properties available in TW12 is 34\n",
      "scraping page 1 from TW13\n",
      "scraping page 2 from TW13\n",
      "------------------------------- SCRAPING COMPLETED FOR TW13\n",
      "Total numbers of properties available in TW13 is 19\n",
      "scraping page 1 from TW14\n",
      "scraping page 2 from TW14\n",
      "------------------------------- SCRAPING COMPLETED FOR TW14\n",
      "Total numbers of properties available in TW14 is 11\n",
      "scraping page 1 from TW16\n",
      "scraping page 2 from TW16\n",
      "scraping page 3 from TW16\n",
      "------------------------------- SCRAPING COMPLETED FOR TW16\n",
      "Total numbers of properties available in TW16 is 23\n",
      "scraping page 1 from TW19\n",
      "------------------------------- SCRAPING COMPLETED FOR TW19\n",
      "Total numbers of properties available in TW19 is 0\n",
      "scraping page 1 from TW2\n",
      "scraping page 2 from TW2\n",
      "scraping page 3 from TW2\n",
      "------------------------------- SCRAPING COMPLETED FOR TW2\n",
      "Total numbers of properties available in TW2 is 25\n",
      "scraping page 1 from TW3\n",
      "------------------------------- SCRAPING COMPLETED FOR TW3\n",
      "Total numbers of properties available in TW3 is 0\n",
      "scraping page 1 from TW4\n",
      "scraping page 2 from TW4\n",
      "------------------------------- SCRAPING COMPLETED FOR TW4\n",
      "Total numbers of properties available in TW4 is 9\n",
      "scraping page 1 from TW5\n",
      "scraping page 2 from TW5\n",
      "scraping page 3 from TW5\n",
      "------------------------------- SCRAPING COMPLETED FOR TW5\n",
      "Total numbers of properties available in TW5 is 15\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: received Inspector.detached event\n  (failed to check if window was closed: disconnected: Unable to receive message from renderer)\n  (Session info: chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00758893+48451]\n\t(No symbol) [0x006EB8A1]\n\t(No symbol) [0x005F5058]\n\t(No symbol) [0x005E924D]\n\t(No symbol) [0x005E8DDD]\n\t(No symbol) [0x005E8175]\n\t(No symbol) [0x005E810C]\n\t(No symbol) [0x005E7A94]\n\t(No symbol) [0x005FBFCA]\n\t(No symbol) [0x0064C67F]\n\t(No symbol) [0x0063A0B6]\n\t(No symbol) [0x00617E08]\n\t(No symbol) [0x00618F2D]\n\tGetHandleVerifier [0x009B8E3A+2540266]\n\tGetHandleVerifier [0x009F8959+2801161]\n\tGetHandleVerifier [0x009F295C+2776588]\n\tGetHandleVerifier [0x007E2280+612144]\n\t(No symbol) [0x006F4F6C]\n\t(No symbol) [0x006F11D8]\n\t(No symbol) [0x006F12BB]\n\t(No symbol) [0x006E4857]\n\tBaseThreadInitThunk [0x750A00C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x76FE7B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76FE7B1E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# loop through postcodes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m postcode \u001b[38;5;129;01min\u001b[39;00m codes\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m198\u001b[39m:][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostcode district\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# call the function and pass the empty DataFrame as an argument\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m \u001b[43mzoopla_rent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpostcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZoopla\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# append the df1 DataFrame to the empty DataFrame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df1], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m, in \u001b[0;36mzoopla_rent\u001b[1;34m(postcodes, Trans_type, website, df)\u001b[0m\n\u001b[0;32m     20\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39m s)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Navigate to the specified URL \u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.zoopla.co.uk/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Maximize the window\u001b[39;00m\n\u001b[0;32m     26\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\undetected_chromedriver\\__init__.py:657\u001b[0m, in \u001b[0;36mChrome.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# if self._get_cdc_props():\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;66;03m#     self._hook_remove_cdc_props()\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:449\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: received Inspector.detached event\n  (failed to check if window was closed: disconnected: Unable to receive message from renderer)\n  (Session info: chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00758893+48451]\n\t(No symbol) [0x006EB8A1]\n\t(No symbol) [0x005F5058]\n\t(No symbol) [0x005E924D]\n\t(No symbol) [0x005E8DDD]\n\t(No symbol) [0x005E8175]\n\t(No symbol) [0x005E810C]\n\t(No symbol) [0x005E7A94]\n\t(No symbol) [0x005FBFCA]\n\t(No symbol) [0x0064C67F]\n\t(No symbol) [0x0063A0B6]\n\t(No symbol) [0x00617E08]\n\t(No symbol) [0x00618F2D]\n\tGetHandleVerifier [0x009B8E3A+2540266]\n\tGetHandleVerifier [0x009F8959+2801161]\n\tGetHandleVerifier [0x009F295C+2776588]\n\tGetHandleVerifier [0x007E2280+612144]\n\t(No symbol) [0x006F4F6C]\n\t(No symbol) [0x006F11D8]\n\t(No symbol) [0x006F12BB]\n\t(No symbol) [0x006E4857]\n\tBaseThreadInitThunk [0x750A00C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x76FE7B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x76FE7B1E+238]\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes.loc[198:]['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = zoopla_rent(postcode, 'Rent', 'Zoopla', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c940ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Zoopla_rent-data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcd63f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode district</th>\n",
       "      <th>Local Areas</th>\n",
       "      <th>Borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>SW7</td>\n",
       "      <td>South Kensington, Knightsbridge</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>SW8</td>\n",
       "      <td>South Lambeth, Vauxhall, Battersea, Clapham, S...</td>\n",
       "      <td>Lambeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SW9</td>\n",
       "      <td>Stockwell, Brixton, Clapham</td>\n",
       "      <td>Lambeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>TN14</td>\n",
       "      <td>Cudham</td>\n",
       "      <td>Bromley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>TN16</td>\n",
       "      <td>Biggin Hill, Tatsfield</td>\n",
       "      <td>Bromley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>WC2B</td>\n",
       "      <td>Drury Lane, Aldwych</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>WC2E</td>\n",
       "      <td>Covent Garden</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>WC2H</td>\n",
       "      <td>Leicester Square</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>WC2N</td>\n",
       "      <td>Charing Cross</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>WC2R</td>\n",
       "      <td>Somerset House</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Postcode district                                        Local Areas   \n",
       "198               SW7                    South Kensington, Knightsbridge  \\\n",
       "199               SW8  South Lambeth, Vauxhall, Battersea, Clapham, S...   \n",
       "200               SW9                        Stockwell, Brixton, Clapham   \n",
       "201              TN14                                             Cudham   \n",
       "202              TN16                             Biggin Hill, Tatsfield   \n",
       "..                ...                                                ...   \n",
       "263              WC2B                                Drury Lane, Aldwych   \n",
       "264              WC2E                                      Covent Garden   \n",
       "265              WC2H                                   Leicester Square   \n",
       "266              WC2N                                      Charing Cross   \n",
       "267              WC2R                                     Somerset House   \n",
       "\n",
       "                    Borough  \n",
       "198  Kensington and Chelsea  \n",
       "199                 Lambeth  \n",
       "200                 Lambeth  \n",
       "201                 Bromley  \n",
       "202                 Bromley  \n",
       "..                      ...  \n",
       "263                  Camden  \n",
       "264             Westminster  \n",
       "265             Westminster  \n",
       "266             Westminster  \n",
       "267             Westminster  \n",
       "\n",
       "[70 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = codes.loc[198:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d6027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
