{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115ef7e4",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white; text-align: center;'>ZOOPLA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e175e1e",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white'> Sales </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65328d",
   "metadata": {},
   "source": [
    "First things first, we will import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4062122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc57114",
   "metadata": {},
   "source": [
    "Next, we will load in the dataset containing the list of postcode for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1195321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv('London postcode districts.xlsx - PC DIST.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a82ab",
   "metadata": {},
   "source": [
    "Now, we will create a function called 'zoopla_sales' to scrap properties that are for sale on the Zoopla website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080b8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoopla_sales(postcodes, Trans_type, website, df):\n",
    "    \"\"\"\n",
    "    This function scrapes property data from Rightmove for a given list of postcodes and transaction type,\n",
    "    and returns the data as a pandas DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    postcodes -- a list of postcodes for which to scrape property data\n",
    "    Trans_type -- the transaction type of the properties to be scraped ('sales' or 'rent')\n",
    "    website -- the name of the website being scraped (in this case, 'Rightmove')\n",
    "    df -- an empty pandas DataFrame to store the scraped data\n",
    "\n",
    "    Returns:\n",
    "    df1 -- a pandas DataFrame containing the scraped property data\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Set the path to the ChromeDriver executable\n",
    "    s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "    \n",
    "    # Launch the ChromeDriver with the specified service\n",
    "    driver = webdriver.Chrome(service= s)\n",
    "    \n",
    "    # Navigate to the specified URL \n",
    "    driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "    # Maximize the window\n",
    "    time.sleep(2)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # Find the search bar  \n",
    "    time.sleep(2.2)\n",
    "    #search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "    try:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@id,'downshift')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    except:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@class,'_1qzmny55 _1ftx2fq8')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    \n",
    "    \n",
    "    # Click the search button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[@class='x8jo560 x8jo562 x8jo56a _1ftx2fq8'][1]\").click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize empty lists for storing scraped data\n",
    "    Trans_type = []\n",
    "    address = []\n",
    "    types = []\n",
    "    bedrooms = []\n",
    "    bathrooms = []\n",
    "    prices = []\n",
    "    desc = []\n",
    "    date_added = []\n",
    "    agent_list = []\n",
    "    property_url = []\n",
    "    website = []\n",
    "    \n",
    "    # Create an empty dataframe to store the scraped data\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "     # Setting the page number to be 1 \n",
    "    i = 1\n",
    "    while True: \n",
    "        # Scrapping data for the required features in the first page\n",
    "        time.sleep(1) \n",
    "        print(\"{} {} {} {}\".format('scraping page', i,'from', postcode ))\n",
    "        \n",
    "        time.sleep(2.1)\n",
    "        try: \n",
    "            driver.find_element(By.XPATH, \"//*[contains(@class,'u94mg1 u94mg4 u94mg9')]\").click()\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "        except:\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        time.sleep(1.4)    \n",
    "        address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "        type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "        bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "        bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "        price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "        desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "        date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "        agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "        property_url_list = driver.current_url\n",
    "        Trans_type_list = Trans_type\n",
    "        website_list = website\n",
    "        for address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item in zip(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n",
    "            address.append(address_item.text)\n",
    "            types.append(type_item.text)\n",
    "            bedrooms.append(bedroom_item.text)\n",
    "            bathrooms.append(bathroom_item.text)\n",
    "            prices.append(price_item.text)\n",
    "            desc.append(desc_item.text)\n",
    "            date_added.append(date_added_item.text)\n",
    "            agent_list.append(agent_list_item.text)\n",
    "            property_url.append(property_url_list)\n",
    "            Trans_type.append(Trans_type_list)\n",
    "            website.append(website_list)\n",
    "\n",
    "\n",
    "        time.sleep(1.3)\n",
    "        # get the height of the page\n",
    "        page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "        \n",
    "        # Cancel the pop-up window\n",
    "        j= i + 1\n",
    "        url = f'https://www.zoopla.co.uk/for-sale/property/{postcode}/?q={postcode}&search_source=home&pn={j}'\n",
    "        if len(address_list) or len(type_list) != 0:\n",
    "            driver.get(url)\n",
    "        else:\n",
    "            print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n",
    "            break\n",
    "        \n",
    "            \n",
    "        #Increment the page number\n",
    "        i += 1\n",
    "        time.sleep(1)\n",
    "                \n",
    "        \n",
    "    # Create a dataframe to store data scrapped for each postcode    \n",
    "    df1 = pd.DataFrame({'Location': postcode, 'Tansaction_Type': 'Sales','Property_Type':types, 'Address' :address, 'Bedrooms': bedrooms, 'Bathrooms':bathrooms, 'Price':prices, 'Description': desc, 'Listing_Date':date_added, 'Agent':agent_list, 'Listing_Source': 'Zoopla', 'listing_URL':property_url})\n",
    "    df1.insert(0, 'Unique_Id', [f'{postcode}S{i+1:05d}ZP' for i in range(len(df1))])\n",
    "    print('Total numbers of properties available in ' + postcode + ' is ' + str(df1.shape[0]))\n",
    "\n",
    "     # Concat the dataframe obtain for all postcodes\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    \n",
    "     # Return a dataframe\n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467a5750",
   "metadata": {},
   "source": [
    "Now, the data for properties available for sale at Zoopla is scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd140770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = zoopla_sales(postcode, 'Sales', 'Zoopla', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7047963d",
   "metadata": {},
   "source": [
    "In case the web scraping breaks while running due to network, we can continue the scrapping process from the last postcode as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42071880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1 from WC1B\n",
      "scraping page 2 from WC1B\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1B\n",
      "Total numbers of properties available in WC1B is 13\n",
      "scraping page 1 from WC1E\n",
      "scraping page 2 from WC1E\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1E\n",
      "Total numbers of properties available in WC1E is 21\n",
      "scraping page 1 from WC1H\n",
      "scraping page 2 from WC1H\n",
      "scraping page 3 from WC1H\n",
      "scraping page 4 from WC1H\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1H\n",
      "Total numbers of properties available in WC1H is 40\n",
      "scraping page 1 from WC1N\n",
      "scraping page 2 from WC1N\n",
      "scraping page 3 from WC1N\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1N\n",
      "Total numbers of properties available in WC1N is 28\n",
      "scraping page 1 from WC1V\n",
      "scraping page 2 from WC1V\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1V\n",
      "Total numbers of properties available in WC1V is 10\n",
      "scraping page 1 from WC1X\n",
      "scraping page 2 from WC1X\n",
      "scraping page 3 from WC1X\n",
      "scraping page 4 from WC1X\n",
      "scraping page 5 from WC1X\n",
      "------------------------------- SCRAPING COMPLETED FOR WC1X\n",
      "Total numbers of properties available in WC1X is 69\n",
      "scraping page 1 from WC2A\n",
      "scraping page 2 from WC2A\n",
      "scraping page 3 from WC2A\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2A\n",
      "Total numbers of properties available in WC2A is 25\n",
      "scraping page 1 from WC2B\n",
      "scraping page 2 from WC2B\n",
      "scraping page 3 from WC2B\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2B\n",
      "Total numbers of properties available in WC2B is 36\n",
      "scraping page 1 from WC2E\n",
      "scraping page 2 from WC2E\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2E\n",
      "Total numbers of properties available in WC2E is 19\n",
      "scraping page 1 from WC2H\n",
      "scraping page 2 from WC2H\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2H\n",
      "Total numbers of properties available in WC2H is 17\n",
      "scraping page 1 from WC2N\n",
      "scraping page 2 from WC2N\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2N\n",
      "Total numbers of properties available in WC2N is 22\n",
      "scraping page 1 from WC2R\n",
      "scraping page 2 from WC2R\n",
      "scraping page 3 from WC2R\n",
      "scraping page 4 from WC2R\n",
      "------------------------------- SCRAPING COMPLETED FOR WC2R\n",
      "Total numbers of properties available in WC2R is 53\n",
      "------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS 353\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes.loc[256:]['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = zoopla_sales(postcode, 'Sales', 'Zoopla', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06866a2",
   "metadata": {},
   "source": [
    "Saving the dataframe into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e44cbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Zoopla_Sales_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985bcc9",
   "metadata": {},
   "source": [
    "Loading the dataset and removing an unwanted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d96b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ZP_sales = pd.read_csv('Zoopla_Sales_data.csv')\n",
    "df_ZP_sales = df_ZP_sales.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6995853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49521, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "df_ZP_sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e582ecc",
   "metadata": {},
   "source": [
    "Almost 50,000 properties were scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee88d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_Id</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tansaction_Type</th>\n",
       "      <th>Property_Type</th>\n",
       "      <th>Address</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "      <th>Listing_Date</th>\n",
       "      <th>Agent</th>\n",
       "      <th>Listing_Source</th>\n",
       "      <th>listing_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR1S00001ZP</td>\n",
       "      <td>BR1</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Bishops Avenue, Bromley, Kent BR1</td>\n",
       "      <td>6 bed semi-detached house for sale</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>£1,250,000</td>\n",
       "      <td>Chain free and newly rennovated to an exceptio...</td>\n",
       "      <td>Listed on 18th May 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/br1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BR1S00002ZP</td>\n",
       "      <td>BR1</td>\n",
       "      <td>Sales</td>\n",
       "      <td>College Road, Bromley BR1</td>\n",
       "      <td>1 bed flat for sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£255,000</td>\n",
       "      <td>Escape the city hustle with this stunning one-...</td>\n",
       "      <td>Listed on 18th May 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/br1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BR1S00003ZP</td>\n",
       "      <td>BR1</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Marian Gardens, Bromley, Kent BR1</td>\n",
       "      <td>2 bed flat for sale</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£550,000</td>\n",
       "      <td>Located in the prestigious Hampton Grange deve...</td>\n",
       "      <td>Listed on 18th May 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/br1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR1S00004ZP</td>\n",
       "      <td>BR1</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Forde Avenue, Bromley, Kent BR1</td>\n",
       "      <td>3 bed terraced house for sale</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£600,000</td>\n",
       "      <td>A very generously proportioned mid terraced th...</td>\n",
       "      <td>Listed on 18th May 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/br1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BR1S00005ZP</td>\n",
       "      <td>BR1</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Ellen Close, Bickley, Bromley BR1</td>\n",
       "      <td>3 bed semi-detached house for sale</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>£525,000</td>\n",
       "      <td>*Guide Price £525,000 - £550,000* A spacious t...</td>\n",
       "      <td>Listed on 18th May 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/br1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49516</th>\n",
       "      <td>WC2RS00049ZP</td>\n",
       "      <td>WC2R</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Strand, Covent Garden, London WC2R</td>\n",
       "      <td>1 bed flat for sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£1,500,000</td>\n",
       "      <td>A one bedroom flat for sale in the luxurious 1...</td>\n",
       "      <td>Listed on 30th Nov 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/WC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49517</th>\n",
       "      <td>WC2RS00050ZP</td>\n",
       "      <td>WC2R</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Strand, Covent Garden WC2R</td>\n",
       "      <td>1 bed flat for sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£1,500,000</td>\n",
       "      <td>A stunning one bedroom, one bathroom apartment...</td>\n",
       "      <td>Listed on 19th Nov 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/WC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49518</th>\n",
       "      <td>WC2RS00051ZP</td>\n",
       "      <td>WC2R</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wren House, 190 The Strand, London WC2R</td>\n",
       "      <td>Studio for sale</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£900,000</td>\n",
       "      <td>This incredibly finished apartment, set in a q...</td>\n",
       "      <td>Listed on 17th Nov 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/WC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49519</th>\n",
       "      <td>WC2RS00052ZP</td>\n",
       "      <td>WC2R</td>\n",
       "      <td>Sales</td>\n",
       "      <td>190 Strand, Strand WC2R</td>\n",
       "      <td>4 bed flat for sale</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£21,300,000</td>\n",
       "      <td>Beautiful Large Penthouse. A New Build Develop...</td>\n",
       "      <td>Listed on 11th Feb 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/WC2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49520</th>\n",
       "      <td>WC2RS00053ZP</td>\n",
       "      <td>WC2R</td>\n",
       "      <td>Sales</td>\n",
       "      <td>13 Arundel Street, London City WC2R</td>\n",
       "      <td>2 bed flat for sale</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>£2,100,000</td>\n",
       "      <td>Located on the world famous Strand, 190 Strand...</td>\n",
       "      <td>Listed on 30th Jan 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoopla</td>\n",
       "      <td>https://www.zoopla.co.uk/for-sale/property/WC2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49521 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unique_Id Location Tansaction_Type  \\\n",
       "0       BR1S00001ZP      BR1           Sales   \n",
       "1       BR1S00002ZP      BR1           Sales   \n",
       "2       BR1S00003ZP      BR1           Sales   \n",
       "3       BR1S00004ZP      BR1           Sales   \n",
       "4       BR1S00005ZP      BR1           Sales   \n",
       "...             ...      ...             ...   \n",
       "49516  WC2RS00049ZP     WC2R           Sales   \n",
       "49517  WC2RS00050ZP     WC2R           Sales   \n",
       "49518  WC2RS00051ZP     WC2R           Sales   \n",
       "49519  WC2RS00052ZP     WC2R           Sales   \n",
       "49520  WC2RS00053ZP     WC2R           Sales   \n",
       "\n",
       "                                 Property_Type  \\\n",
       "0            Bishops Avenue, Bromley, Kent BR1   \n",
       "1                    College Road, Bromley BR1   \n",
       "2            Marian Gardens, Bromley, Kent BR1   \n",
       "3              Forde Avenue, Bromley, Kent BR1   \n",
       "4            Ellen Close, Bickley, Bromley BR1   \n",
       "...                                        ...   \n",
       "49516       Strand, Covent Garden, London WC2R   \n",
       "49517               Strand, Covent Garden WC2R   \n",
       "49518  Wren House, 190 The Strand, London WC2R   \n",
       "49519                  190 Strand, Strand WC2R   \n",
       "49520      13 Arundel Street, London City WC2R   \n",
       "\n",
       "                                  Address  Bedrooms  Bathrooms        Price  \\\n",
       "0      6 bed semi-detached house for sale       6.0        2.0   £1,250,000   \n",
       "1                     1 bed flat for sale       1.0        1.0     £255,000   \n",
       "2                     2 bed flat for sale       2.0        1.0     £550,000   \n",
       "3           3 bed terraced house for sale       3.0        1.0     £600,000   \n",
       "4      3 bed semi-detached house for sale       3.0        2.0     £525,000   \n",
       "...                                   ...       ...        ...          ...   \n",
       "49516                 1 bed flat for sale       1.0        1.0   £1,500,000   \n",
       "49517                 1 bed flat for sale       1.0        1.0   £1,500,000   \n",
       "49518                     Studio for sale       1.0        1.0     £900,000   \n",
       "49519                 4 bed flat for sale       4.0        1.0  £21,300,000   \n",
       "49520                 2 bed flat for sale       2.0        1.0   £2,100,000   \n",
       "\n",
       "                                             Description  \\\n",
       "0      Chain free and newly rennovated to an exceptio...   \n",
       "1      Escape the city hustle with this stunning one-...   \n",
       "2      Located in the prestigious Hampton Grange deve...   \n",
       "3      A very generously proportioned mid terraced th...   \n",
       "4      *Guide Price £525,000 - £550,000* A spacious t...   \n",
       "...                                                  ...   \n",
       "49516  A one bedroom flat for sale in the luxurious 1...   \n",
       "49517  A stunning one bedroom, one bathroom apartment...   \n",
       "49518  This incredibly finished apartment, set in a q...   \n",
       "49519  Beautiful Large Penthouse. A New Build Develop...   \n",
       "49520  Located on the world famous Strand, 190 Strand...   \n",
       "\n",
       "                  Listing_Date  Agent Listing_Source  \\\n",
       "0      Listed on 18th May 2023    NaN         Zoopla   \n",
       "1      Listed on 18th May 2023    NaN         Zoopla   \n",
       "2      Listed on 18th May 2023    NaN         Zoopla   \n",
       "3      Listed on 18th May 2023    NaN         Zoopla   \n",
       "4      Listed on 18th May 2023    NaN         Zoopla   \n",
       "...                        ...    ...            ...   \n",
       "49516  Listed on 30th Nov 2020    NaN         Zoopla   \n",
       "49517  Listed on 19th Nov 2020    NaN         Zoopla   \n",
       "49518  Listed on 17th Nov 2020    NaN         Zoopla   \n",
       "49519  Listed on 11th Feb 2020    NaN         Zoopla   \n",
       "49520  Listed on 30th Jan 2020    NaN         Zoopla   \n",
       "\n",
       "                                             listing_URL  \n",
       "0      https://www.zoopla.co.uk/for-sale/property/br1...  \n",
       "1      https://www.zoopla.co.uk/for-sale/property/br1...  \n",
       "2      https://www.zoopla.co.uk/for-sale/property/br1...  \n",
       "3      https://www.zoopla.co.uk/for-sale/property/br1...  \n",
       "4      https://www.zoopla.co.uk/for-sale/property/br1...  \n",
       "...                                                  ...  \n",
       "49516  https://www.zoopla.co.uk/for-sale/property/WC2...  \n",
       "49517  https://www.zoopla.co.uk/for-sale/property/WC2...  \n",
       "49518  https://www.zoopla.co.uk/for-sale/property/WC2...  \n",
       "49519  https://www.zoopla.co.uk/for-sale/property/WC2...  \n",
       "49520  https://www.zoopla.co.uk/for-sale/property/WC2...  \n",
       "\n",
       "[49521 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ZP_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72edbcd",
   "metadata": {},
   "source": [
    "<h1 style='background-color: BLACK; padding: 10px; color: white'> Rent </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5be01",
   "metadata": {},
   "source": [
    "Now, we will create a function called 'zoopla_rent' to scrap properties that are for rent on the Zoopla website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91431634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoopla_rent(postcodes, Trans_type, website, df):\n",
    "    \"\"\"\n",
    "    This function scrapes property data from Rightmove for a given list of postcodes and transaction type,\n",
    "    and returns the data as a pandas DataFrame.\n",
    "\n",
    "    Arguments:\n",
    "    postcodes -- a list of postcodes for which to scrape property data\n",
    "    Trans_type -- the transaction type of the properties to be scraped ('sales' or 'rent')\n",
    "    website -- the name of the website being scraped (in this case, 'Rightmove')\n",
    "    df -- an empty pandas DataFrame to store the scraped data\n",
    "\n",
    "    Returns:\n",
    "    df1 -- a pandas DataFrame containing the scraped property data\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Set the path to the ChromeDriver executable\n",
    "    s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "    \n",
    "    # Launch the ChromeDriver with the specified service\n",
    "    driver = webdriver.Chrome(service= s)\n",
    "    \n",
    "    # Navigate to the specified URL \n",
    "    driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "    # Maximize the window\n",
    "    time.sleep(2)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    #Click the rent button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[contains(@id,'radix-:Reckt6:-trigger-to-rent')]\").click()\n",
    "\n",
    "    # Find the search bar  \n",
    "    time.sleep(2.2)\n",
    "    #search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "    try:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@id,'downshift')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    except:\n",
    "        search = driver.find_element(By.XPATH, \"//input[contains(@class,'_1qzmny55 _1ftx2fq8')]\")\n",
    "        search.send_keys(postcode)\n",
    "        time.sleep(1.3)\n",
    "    \n",
    "    \n",
    "    # Click the search button\n",
    "    time.sleep(1.5)   \n",
    "    driver.find_element(By.XPATH, \"//button[@class='x8jo560 x8jo562 x8jo56a _1ftx2fq8'][1]\").click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Initialize empty lists for storing scraped data\n",
    "    Trans_type = []\n",
    "    address = []\n",
    "    types = []\n",
    "    bedrooms = []\n",
    "    bathrooms = []\n",
    "    prices = []\n",
    "    desc = []\n",
    "    date_added = []\n",
    "    agent_list = []\n",
    "    property_url = []\n",
    "    website = []\n",
    "    \n",
    "    # Create an empty dataframe to store the scraped data\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "     # Setting the page number to be 1 \n",
    "    i = 1\n",
    "    while True: \n",
    "        # Scrapping data for the required features in the first page\n",
    "        time.sleep(1) \n",
    "        print(\"{} {} {} {}\".format('scraping page', i,'from', postcode ))\n",
    "        \n",
    "        time.sleep(2.1)\n",
    "        try: \n",
    "            driver.find_element(By.XPATH, \"//*[contains(@class,'u94mg1 u94mg4 u94mg9')]\").click()\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "        except:\n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        time.sleep(1.4)    \n",
    "        address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "        type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "        bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "        bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "        price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "        desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "        date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "        agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "        property_url_list = driver.current_url\n",
    "        Trans_type_list = Trans_type\n",
    "        website_list = website\n",
    "        for address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item in zip(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n",
    "            address.append(address_item.text)\n",
    "            types.append(type_item.text)\n",
    "            bedrooms.append(bedroom_item.text)\n",
    "            bathrooms.append(bathroom_item.text)\n",
    "            prices.append(price_item.text)\n",
    "            desc.append(desc_item.text)\n",
    "            date_added.append(date_added_item.text)\n",
    "            agent_list.append(agent_list_item.text)\n",
    "            property_url.append(property_url_list)\n",
    "            Trans_type.append(Trans_type_list)\n",
    "            website.append(website_list)\n",
    "\n",
    "\n",
    "        time.sleep(1.3)\n",
    "        # get the height of the page\n",
    "        page_height = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "\n",
    "        \n",
    "        # Cancel the pop-up window\n",
    "        j= i + 1        \n",
    "        url = f'https://www.zoopla.co.uk/to-rent/property/{postcode}/?price_frequency=per_month&q={postcode}&search_source=home&pn={j}'\n",
    "        if len(address_list) or len(type_list) != 0:\n",
    "            driver.get(url)\n",
    "        else:\n",
    "            print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)\n",
    "            break\n",
    "        \n",
    "            \n",
    "        #Increment the page number\n",
    "        i += 1\n",
    "        time.sleep(1)\n",
    "                \n",
    "        \n",
    "    # Create a dataframe to store data scrapped for each postcode    \n",
    "    df1 = pd.DataFrame({'Location': postcode, 'Tansaction_Type': 'Rent','Property_Type':types, 'Address' :address, 'Bedrooms': bedrooms, 'Bathrooms':bathrooms, 'Price':prices, 'Description': desc, 'Listing_Date':date_added, 'Agent':agent_list, 'Listing_Source': 'Zoopla', 'listing_URL':property_url})\n",
    "    df1.insert(0, 'Unique_Id', [f'{postcode}R{i+1:05d}ZP' for i in range(len(df1))])\n",
    "    print('Total numbers of properties available in ' + postcode + ' is ' + str(df1.shape[0]))\n",
    "\n",
    "     # Concat the dataframe obtain for all postcodes\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "    \n",
    "     # Return a dataframe\n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c7ff6",
   "metadata": {},
   "source": [
    "Now, the data for properties available for rent at Zoopla is scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = zoopla_rent(postcode, 'Rent', 'Zoopla', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba2a15",
   "metadata": {},
   "source": [
    "In case the web scraping breaks while running due to network, we can continue the scrapping process from the last postcode as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29b459a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1 from TW6\n",
      "scraping page 2 from TW6\n",
      "------------------------------- SCRAPING COMPLETED FOR TW6\n",
      "Total numbers of properties available in TW6 is 12\n",
      "scraping page 1 from TW7\n",
      "scraping page 2 from TW7\n",
      "scraping page 3 from TW7\n",
      "scraping page 4 from TW7\n",
      "------------------------------- SCRAPING COMPLETED FOR TW7\n",
      "Total numbers of properties available in TW7 is 54\n",
      "scraping page 1 from TW8\n",
      "scraping page 2 from TW8\n",
      "scraping page 3 from TW8\n",
      "scraping page 4 from TW8\n",
      "scraping page 5 from TW8\n",
      "scraping page 6 from TW8\n",
      "scraping page 7 from TW8\n",
      "scraping page 8 from TW8\n",
      "scraping page 9 from TW8\n",
      "scraping page 10 from TW8\n",
      "------------------------------- SCRAPING COMPLETED FOR TW8\n",
      "Total numbers of properties available in TW8 is 136\n",
      "scraping page 1 from TW9\n",
      "scraping page 2 from TW9\n",
      "scraping page 3 from TW9\n",
      "scraping page 4 from TW9\n",
      "scraping page 5 from TW9\n",
      "------------------------------- SCRAPING COMPLETED FOR TW9\n",
      "Total numbers of properties available in TW9 is 63\n",
      "scraping page 1 from UB1\n",
      "scraping page 2 from UB1\n",
      "scraping page 3 from UB1\n",
      "------------------------------- SCRAPING COMPLETED FOR UB1\n",
      "Total numbers of properties available in UB1 is 23\n",
      "scraping page 1 from UB10\n",
      "scraping page 2 from UB10\n",
      "scraping page 3 from UB10\n",
      "------------------------------- SCRAPING COMPLETED FOR UB10\n",
      "Total numbers of properties available in UB10 is 26\n",
      "scraping page 1 from UB11\n",
      "scraping page 2 from UB11\n",
      "------------------------------- SCRAPING COMPLETED FOR UB11\n",
      "Total numbers of properties available in UB11 is 14\n",
      "scraping page 1 from UB2\n",
      "scraping page 2 from UB2\n",
      "scraping page 3 from UB2\n",
      "scraping page 4 from UB2\n",
      "------------------------------- SCRAPING COMPLETED FOR UB2\n",
      "Total numbers of properties available in UB2 is 55\n",
      "scraping page 1 from UB3\n",
      "scraping page 2 from UB3\n",
      "scraping page 3 from UB3\n",
      "scraping page 4 from UB3\n",
      "------------------------------- SCRAPING COMPLETED FOR UB3\n",
      "Total numbers of properties available in UB3 is 27\n",
      "scraping page 1 from UB4\n",
      "scraping page 2 from UB4\n",
      "------------------------------- SCRAPING COMPLETED FOR UB4\n",
      "Total numbers of properties available in UB4 is 12\n",
      "scraping page 1 from UB5\n",
      "scraping page 2 from UB5\n",
      "scraping page 3 from UB5\n",
      "------------------------------- SCRAPING COMPLETED FOR UB5\n",
      "Total numbers of properties available in UB5 is 17\n",
      "scraping page 1 from UB6\n",
      "scraping page 2 from UB6\n",
      "scraping page 3 from UB6\n",
      "scraping page 4 from UB6\n",
      "------------------------------- SCRAPING COMPLETED FOR UB6\n",
      "Total numbers of properties available in UB6 is 39\n",
      "scraping page 1 from UB7\n",
      "scraping page 2 from UB7\n",
      "scraping page 3 from UB7\n",
      "------------------------------- SCRAPING COMPLETED FOR UB7\n",
      "Total numbers of properties available in UB7 is 20\n",
      "scraping page 1 from UB8\n",
      "scraping page 2 from UB8\n",
      "scraping page 3 from UB8\n",
      "scraping page 4 from UB8\n",
      "scraping page 5 from UB8\n",
      "------------------------------- SCRAPING COMPLETED FOR UB8\n",
      "Total numbers of properties available in UB8 is 68\n",
      "scraping page 1 from UB9\n",
      "scraping page 2 from UB9\n",
      "------------------------------- SCRAPING COMPLETED FOR UB9\n",
      "Total numbers of properties available in UB9 is 19\n",
      "scraping page 1 from W10\n",
      "scraping page 2 from W10\n",
      "scraping page 3 from W10\n",
      "scraping page 4 from W10\n",
      "scraping page 5 from W10\n",
      "scraping page 6 from W10\n",
      "------------------------------- SCRAPING COMPLETED FOR W10\n",
      "Total numbers of properties available in W10 is 73\n",
      "scraping page 1 from W11\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00DB8893+48451]\n\t(No symbol) [0x00D4B8A1]\n\t(No symbol) [0x00C55058]\n\t(No symbol) [0x00C3D073]\n\t(No symbol) [0x00C9DEBB]\n\t(No symbol) [0x00CABFD3]\n\t(No symbol) [0x00C9A0B6]\n\t(No symbol) [0x00C77E08]\n\t(No symbol) [0x00C78F2D]\n\tGetHandleVerifier [0x01018E3A+2540266]\n\tGetHandleVerifier [0x01058959+2801161]\n\tGetHandleVerifier [0x0105295C+2776588]\n\tGetHandleVerifier [0x00E42280+612144]\n\t(No symbol) [0x00D54F6C]\n\t(No symbol) [0x00D511D8]\n\t(No symbol) [0x00D512BB]\n\t(No symbol) [0x00D44857]\n\tBaseThreadInitThunk [0x771A00C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77587B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77587B1E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# loop through postcodes\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m postcode \u001b[38;5;129;01min\u001b[39;00m codes\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m215\u001b[39m:][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPostcode district\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# call the function and pass the empty DataFrame as an argument\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m \u001b[43mzoopla_rent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpostcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mZoopla\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# append the df1 DataFrame to the empty DataFrame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df1], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mzoopla_rent\u001b[1;34m(postcodes, Trans_type, website, df)\u001b[0m\n\u001b[0;32m     94\u001b[0m website_list \u001b[38;5;241m=\u001b[39m website\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m address_item, type_item, bedroom_item, bathroom_item, price_item, desc_item, date_added_item, agent_list_item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(address_list, type_list, bedroom_list, bathroom_list, price_list, desc_list, date_added_list, agent_list_list):\n\u001b[1;32m---> 96\u001b[0m     address\u001b[38;5;241m.\u001b[39mappend(\u001b[43maddress_item\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n\u001b[0;32m     97\u001b[0m     types\u001b[38;5;241m.\u001b[39mappend(type_item\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     98\u001b[0m     bedrooms\u001b[38;5;241m.\u001b[39mappend(bedroom_item\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webelement.py:90\u001b[0m, in \u001b[0;36mWebElement.text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;124;03m\"\"\"The text of the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_ELEMENT_TEXT\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webelement.py:403\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    401\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    402\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=113.0.5672.127)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00DB8893+48451]\n\t(No symbol) [0x00D4B8A1]\n\t(No symbol) [0x00C55058]\n\t(No symbol) [0x00C3D073]\n\t(No symbol) [0x00C9DEBB]\n\t(No symbol) [0x00CABFD3]\n\t(No symbol) [0x00C9A0B6]\n\t(No symbol) [0x00C77E08]\n\t(No symbol) [0x00C78F2D]\n\tGetHandleVerifier [0x01018E3A+2540266]\n\tGetHandleVerifier [0x01058959+2801161]\n\tGetHandleVerifier [0x0105295C+2776588]\n\tGetHandleVerifier [0x00E42280+612144]\n\t(No symbol) [0x00D54F6C]\n\t(No symbol) [0x00D511D8]\n\t(No symbol) [0x00D512BB]\n\t(No symbol) [0x00D44857]\n\tBaseThreadInitThunk [0x771A00C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77587B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77587B1E+238]\n"
     ]
    }
   ],
   "source": [
    "# create an empty DataFrame outside the function\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through postcodes\n",
    "for postcode in codes.loc[231:]['Postcode district']:\n",
    "    # call the function and pass the empty DataFrame as an argument\n",
    "    df1 = zoopla_rent(postcode, 'Rent', 'Zoopla', df)\n",
    "    # append the df1 DataFrame to the empty DataFrame\n",
    "    df = pd.concat([df, df1], ignore_index=True)\n",
    "print('------------------------ WEB SCRAPING COMPLETED: OVERALL TOTAL NUMBER OF PROPERTIES SCRAPED IS ' + str(df.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c940ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Zoopla_rent-data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcd63f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postcode district</th>\n",
       "      <th>Local Areas</th>\n",
       "      <th>Borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>W11</td>\n",
       "      <td>Notting Hill, Holland Park</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>W12</td>\n",
       "      <td>Shepherds Bush, White City</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>W13</td>\n",
       "      <td>West Ealing, Northfields</td>\n",
       "      <td>Ealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>W14</td>\n",
       "      <td>West Kensington, Kensington Olympia, Holland Park</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>W1B</td>\n",
       "      <td>Portland Street, Regent Street</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>W1C</td>\n",
       "      <td>Oxford Street (west)</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>W1D</td>\n",
       "      <td>Soho (south east), Chinatown, Soho Square</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>W1F</td>\n",
       "      <td>Soho (north west)</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>W1G</td>\n",
       "      <td>Harley Street</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>W1H</td>\n",
       "      <td>Marylebone</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>W1J</td>\n",
       "      <td>Mayfair (south), Piccadilly, Royal Academy</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>W1K</td>\n",
       "      <td>Mayfair (north), Grosvenor Square</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>W1S</td>\n",
       "      <td>Hanover Square, Savile Row</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>W1T</td>\n",
       "      <td>Fitzrovia, Tottenham Court Road</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>W1U</td>\n",
       "      <td>Marylebone</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>W1W</td>\n",
       "      <td>Great Portland Street, Fitzrovia</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>W2</td>\n",
       "      <td>Paddington, Bayswater, Hyde Park, Westbourne G...</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>W3</td>\n",
       "      <td>Acton, East Acton, Park Royal, West Acton</td>\n",
       "      <td>Ealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>W4</td>\n",
       "      <td>Chiswick, Gunnersbury, Turnham Green, Bedford ...</td>\n",
       "      <td>Hounslow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>W5</td>\n",
       "      <td>Ealing, Park Royal</td>\n",
       "      <td>Ealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>W6</td>\n",
       "      <td>Hammersmith, Ravenscourt Park</td>\n",
       "      <td>Hammersmith and Fulham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>W7</td>\n",
       "      <td>Hanwell, Boston Manor</td>\n",
       "      <td>Ealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>W8</td>\n",
       "      <td>Kensington, Holland Park</td>\n",
       "      <td>Kensington and Chelsea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>W9</td>\n",
       "      <td>Maida Vale, Little Venice</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>WC1A</td>\n",
       "      <td>New Oxford Street</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>WC1B</td>\n",
       "      <td>Bloomsbury, British Museum</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>WC1E</td>\n",
       "      <td>University College London</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>WC1H</td>\n",
       "      <td>St Pancras</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>WC1N</td>\n",
       "      <td>Great Ormond Street Hospital</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>WC1V</td>\n",
       "      <td>High Holborn</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>WC1X</td>\n",
       "      <td>Kings Cross, Finsbury (west)</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>WC2A</td>\n",
       "      <td>Lincoln's Inn Fields, Royal Courts of Justice</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>WC2B</td>\n",
       "      <td>Drury Lane, Aldwych</td>\n",
       "      <td>Camden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>WC2E</td>\n",
       "      <td>Covent Garden</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>WC2H</td>\n",
       "      <td>Leicester Square</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>WC2N</td>\n",
       "      <td>Charing Cross</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>WC2R</td>\n",
       "      <td>Somerset House</td>\n",
       "      <td>Westminster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Postcode district                                        Local Areas  \\\n",
       "231               W11                         Notting Hill, Holland Park   \n",
       "232               W12                         Shepherds Bush, White City   \n",
       "233               W13                           West Ealing, Northfields   \n",
       "234               W14  West Kensington, Kensington Olympia, Holland Park   \n",
       "235               W1B                     Portland Street, Regent Street   \n",
       "236               W1C                               Oxford Street (west)   \n",
       "237               W1D          Soho (south east), Chinatown, Soho Square   \n",
       "238               W1F                                  Soho (north west)   \n",
       "239               W1G                                      Harley Street   \n",
       "240               W1H                                         Marylebone   \n",
       "241               W1J         Mayfair (south), Piccadilly, Royal Academy   \n",
       "242               W1K                  Mayfair (north), Grosvenor Square   \n",
       "243               W1S                         Hanover Square, Savile Row   \n",
       "244               W1T                    Fitzrovia, Tottenham Court Road   \n",
       "245               W1U                                         Marylebone   \n",
       "246               W1W                   Great Portland Street, Fitzrovia   \n",
       "247                W2  Paddington, Bayswater, Hyde Park, Westbourne G...   \n",
       "248                W3          Acton, East Acton, Park Royal, West Acton   \n",
       "249                W4  Chiswick, Gunnersbury, Turnham Green, Bedford ...   \n",
       "250                W5                                 Ealing, Park Royal   \n",
       "251                W6                      Hammersmith, Ravenscourt Park   \n",
       "252                W7                              Hanwell, Boston Manor   \n",
       "253                W8                           Kensington, Holland Park   \n",
       "254                W9                          Maida Vale, Little Venice   \n",
       "255              WC1A                                  New Oxford Street   \n",
       "256              WC1B                         Bloomsbury, British Museum   \n",
       "257              WC1E                          University College London   \n",
       "258              WC1H                                         St Pancras   \n",
       "259              WC1N                       Great Ormond Street Hospital   \n",
       "260              WC1V                                       High Holborn   \n",
       "261              WC1X                       Kings Cross, Finsbury (west)   \n",
       "262              WC2A      Lincoln's Inn Fields, Royal Courts of Justice   \n",
       "263              WC2B                                Drury Lane, Aldwych   \n",
       "264              WC2E                                      Covent Garden   \n",
       "265              WC2H                                   Leicester Square   \n",
       "266              WC2N                                      Charing Cross   \n",
       "267              WC2R                                     Somerset House   \n",
       "\n",
       "                    Borough  \n",
       "231  Kensington and Chelsea  \n",
       "232  Hammersmith and Fulham  \n",
       "233                  Ealing  \n",
       "234  Kensington and Chelsea  \n",
       "235             Westminster  \n",
       "236             Westminster  \n",
       "237             Westminster  \n",
       "238             Westminster  \n",
       "239             Westminster  \n",
       "240             Westminster  \n",
       "241             Westminster  \n",
       "242             Westminster  \n",
       "243             Westminster  \n",
       "244                  Camden  \n",
       "245             Westminster  \n",
       "246             Westminster  \n",
       "247             Westminster  \n",
       "248                  Ealing  \n",
       "249                Hounslow  \n",
       "250                  Ealing  \n",
       "251  Hammersmith and Fulham  \n",
       "252                  Ealing  \n",
       "253  Kensington and Chelsea  \n",
       "254             Westminster  \n",
       "255                  Camden  \n",
       "256                  Camden  \n",
       "257                  Camden  \n",
       "258                  Camden  \n",
       "259                  Camden  \n",
       "260                  Camden  \n",
       "261                  Camden  \n",
       "262                  Camden  \n",
       "263                  Camden  \n",
       "264             Westminster  \n",
       "265             Westminster  \n",
       "266             Westminster  \n",
       "267             Westminster  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = codes.loc[231:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125d6027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to the ChromeDriver executable\n",
    "s = Service(\"C:\\\\Users\\\\user\\\\Downloads\\\\Set ups\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "\n",
    "# Launch the ChromeDriver with the specified service\n",
    "driver = webdriver.Chrome(service= s)\n",
    "\n",
    "# Navigate to the specified URL \n",
    "driver.get('https://www.zoopla.co.uk/') \n",
    "\n",
    "# Click to cancel the pop-up window and maximize the window\n",
    "#driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div/div/div[2]/button').click()\n",
    "time.sleep(2)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Find the search bar  \n",
    "time.sleep(1.2)\n",
    "search = driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[1]/div/div/div/div/div/div/input')\n",
    "search.send_keys('BR1')\n",
    "time.sleep(1.3)\n",
    "\n",
    "# Click the search button\n",
    "time.sleep(3)\n",
    "driver.find_element(By.XPATH, '/html/body/div[3]/div/div[1]/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/div/form/div/div[2]/button').click()\n",
    "\n",
    "time.sleep(3)\n",
    "Trans_type = []\n",
    "address = []\n",
    "types = []\n",
    "bedrooms = []\n",
    "bathrooms = []\n",
    "prices = []\n",
    "desc = []\n",
    "date_added = []\n",
    "agent_list = []\n",
    "property_url = []\n",
    "website = []\n",
    "\n",
    "address_list =driver.find_elements(By.XPATH, \"//h2[contains(@class,'_1ankud51 _1ftx2fq8')]\")\n",
    "type_list =driver.find_elements(By.XPATH, \"//h3[contains(@class,'_1ankud52 _1ftx2fq9')]\")\n",
    "bedroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[1]//span[2]\")\n",
    "bathroom_list =driver.find_elements(By.XPATH, \"//div[contains(@id,'listing')]//li[3]//span[2]\")\n",
    "price_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_170k6632 _1ftx2fq6')]\")\n",
    "desc_list =driver.find_elements(By.XPATH, \"//p[contains(@class,'_1ankud53 _1ftx2fq9')]\")\n",
    "date_added_list =driver.find_elements(By.XPATH, \"//li[contains(@class,'_18cib8e1')]\")\n",
    "agent_list_list =driver.find_elements(By.XPATH, \"//img[contains(@class,'_12bxhf70')]\")\n",
    "\n",
    "for ad in address_list:\n",
    "    address.append(ad.text)\n",
    "print(address)\n",
    "\n",
    "                          \n",
    "for ad in type_list:\n",
    "    types.append(ad.text)\n",
    "print(types)                                  \n",
    "\n",
    "for ad in bedroom_list:\n",
    "    bedrooms.append(ad.text)\n",
    "print(bedrooms)\n",
    "                              \n",
    "for ad in bathroom_list:\n",
    "    bathrooms.append(ad.text)\n",
    "print(bathrooms)\n",
    "\n",
    "\n",
    "for ad in price_list:\n",
    "    prices.append(ad.text)\n",
    "print(prices)\n",
    "\n",
    "\n",
    "for ad in desc_list:\n",
    "    desc.append(ad.text)\n",
    "print(desc)\n",
    "\n",
    "\n",
    "for ad in date_added_list:\n",
    "    date_added.append(ad.text)\n",
    "print(date_added)\n",
    "\n",
    "for ad in agent_list_list:\n",
    "    agent_list.append(ad.get_attribute('alt'))\n",
    "print(agent_list)\n",
    "\n",
    "print(len(address))\n",
    "print(len(types))\n",
    "print(len(bedrooms))\n",
    "print(len(bathrooms))\n",
    "print(len(prices))\n",
    "print(len(desc))\n",
    "print(len(date_added))\n",
    "print(len(agent_list))\n",
    "\n",
    "url = 'https://www.zoopla.co.uk/for-sale/property/br1/?q=BR1&search_source=home&pn=2'\n",
    "if len(address_list) and len(type_list) != 0:\n",
    "    driver.get(url)\n",
    "else:\n",
    "    print('------------------------------- SCRAPING COMPLETED FOR ' + postcode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
